\relax 
\catcode `"\active 
\select@language{ngerman}
\@writefile{toc}{\select@language{ngerman}}
\@writefile{lof}{\select@language{ngerman}}
\@writefile{lot}{\select@language{ngerman}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Classification}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Rules}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}How badly does a bad decision function perform?}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}How good can a decision function perform in an uncertain environment?}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Discriminative vs. Generative models}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Nearest Neighbor Classification}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.1}Performance Analysis of NN classifier}{8}}
\@writefile{toc}{\contentsline {paragraph}{finite sample analysis}{8}}
\@writefile{toc}{\contentsline {paragraph}{Cross Validation}{10}}
\@writefile{toc}{\contentsline {paragraph}{Asymptotic Analysis}{11}}
\@writefile{toc}{\contentsline {paragraph}{1)}{11}}
\@writefile{toc}{\contentsline {paragraph}{2)}{12}}
\@writefile{toc}{\contentsline {paragraph}{3)}{12}}
\@writefile{toc}{\contentsline {paragraph}{4)}{12}}
\@writefile{toc}{\contentsline {paragraph}{5)}{13}}
\@writefile{toc}{\contentsline {paragraph}{6)}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.2}Limitations of Nearest Neighbor Classifier}{14}}
\@writefile{toc}{\contentsline {paragraph}{1.}{14}}
\@writefile{toc}{\contentsline {paragraph}{2.}{14}}
\@writefile{toc}{\contentsline {paragraph}{3.}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Quadratic and Linear Discriminant Analysis}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.1}Motivation}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.2}QDA}{15}}
\@writefile{toc}{\contentsline {paragraph}{Gaussian distribution}{16}}
\@writefile{toc}{\contentsline {paragraph}{How to fit a multi-dim. Gaussian}{16}}
\@writefile{toc}{\contentsline {paragraph}{How to fit a Gaussian?}{17}}
\@writefile{toc}{\contentsline {paragraph}{Training of QDA}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.3}LDA Linear Discriminant Analysis}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.4}LDA}{20}}
\@writefile{toc}{\contentsline {paragraph}{1.}{20}}
\@writefile{toc}{\contentsline {paragraph}{2.}{20}}
\@writefile{toc}{\contentsline {paragraph}{3.}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}Logistic Regression LR}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.7.1}Learning LR}{22}}
\@writefile{toc}{\contentsline {paragraph}{Find w}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8}Histogramms and Density Trees}{23}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.8.1}Introduction}{23}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.8.2}Naive Bayes}{27}}
\@writefile{toc}{\contentsline {paragraph}{Variant:}{28}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.8.3}Density trees}{28}}
\@writefile{toc}{\contentsline {paragraph}{exhaustive search:}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Regression}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Introduction}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Ordinary Least Squares (OLS)}{32}}
\@writefile{toc}{\contentsline {paragraph}{Theorem:}{36}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Computer Topography}{36}}
\@writefile{toc}{\contentsline {paragraph}{Wiederholung Computer Tomography}{37}}
\@writefile{toc}{\contentsline {paragraph}{Step 1}{37}}
\@writefile{toc}{\contentsline {paragraph}{Step 2}{37}}
\@writefile{toc}{\contentsline {paragraph}{Step 3}{37}}
\@writefile{toc}{\contentsline {paragraph}{Step 4}{37}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Different $Y_i$ have different noise level $\sigma _i$}{38}}
\@writefile{toc}{\contentsline {paragraph}{Case 1:}{38}}
\@writefile{toc}{\contentsline {paragraph}{But:}{38}}
\@writefile{toc}{\contentsline {paragraph}{Case 2}{38}}
\@writefile{toc}{\contentsline {paragraph}{Case 3:}{39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}If both Y and X are noisy - Total Least Squares (TLS)}{40}}
\@writefile{toc}{\contentsline {paragraph}{Formal definition of optimization problem}{40}}
\@writefile{toc}{\contentsline {paragraph}{Theorem: }{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Total Least Squares}{41}}
\@writefile{toc}{\contentsline {paragraph}{OLS:}{41}}
\@writefile{toc}{\contentsline {paragraph}{TLS:}{41}}
\@writefile{toc}{\contentsline {paragraph}{Intuitive Interpretation:}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}The linear system is underdetermined $\Rightarrow $ Regularization}{41}}
\@writefile{toc}{\contentsline {paragraph}{Case 1:}{41}}
\@writefile{toc}{\contentsline {paragraph}{Case 2:}{41}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Bias-Variance Trade-Off:}{42}}
\@writefile{toc}{\contentsline {paragraph}{Application of OLS:}{42}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}Ridge Regression}{44}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.3}Sparse Regression}{46}}
\@writefile{toc}{\contentsline {paragraph}{Approximation algorithm:}{46}}
\@writefile{toc}{\contentsline {paragraph}{Application of sparse regression - Topic discovery}{47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Non-linear Regression}{47}}
\@writefile{toc}{\contentsline {paragraph}{Example 1 - XOR Problem}{48}}
\@writefile{toc}{\contentsline {paragraph}{Example 2 - Fitting a circle}{48}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.1}Levenberg-Marquart Algorithm}{49}}
